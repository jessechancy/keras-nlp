{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RoBERTaCheckpointConversion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "9jk3R6CtkhZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_nlp\n",
        "import torch"
      ],
      "metadata": {
        "id": "BsM0juhxkmfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model"
      ],
      "metadata": {
        "id": "-hwXXa0FkoOz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhAofrvikc71"
      },
      "outputs": [],
      "source": [
        "class RoBERTaModel(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size, #50265\n",
        "        num_layers=12,\n",
        "        hidden_size=768,\n",
        "        dropout=0.1,\n",
        "        num_attention_heads=12,\n",
        "        inner_size=3072,\n",
        "        inner_activation=\"gelu\",\n",
        "        initializer_range=0.02,\n",
        "        max_sequence_length=512,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.inner_size = inner_size\n",
        "        self.inner_activation = keras.activations.get(inner_activation)\n",
        "        self.initializer_range = initializer_range\n",
        "        self.initializer = keras.initializers.TruncatedNormal(\n",
        "            stddev=initializer_range\n",
        "        )\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self._token_and_position_embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "            vocabulary_size=vocab_size,\n",
        "            sequence_length=max_sequence_length,\n",
        "            embedding_dim=hidden_size,\n",
        "            name=\"token_and_position_embeddings\"\n",
        "        )\n",
        "\n",
        "        self._embedding_norm_layer = keras.layers.LayerNormalization(\n",
        "            name=\"embeddings/layer_norm\",\n",
        "            axis=-1,\n",
        "            epsilon=1e-5,\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        self._embedding_dropout = keras.layers.Dropout(\n",
        "            rate=dropout, name=\"embedding_dropout\"\n",
        "        )\n",
        "\n",
        "        self._transformer_layers = []\n",
        "        for i in range(num_layers):\n",
        "            layer = keras_nlp.layers.TransformerEncoder(\n",
        "                num_heads=num_attention_heads,\n",
        "                intermediate_dim=inner_size,\n",
        "                activation=self.inner_activation,\n",
        "                dropout=dropout,\n",
        "                kernel_initializer=self.initializer,\n",
        "                name=\"transformer/layer_%d\" % i,\n",
        "            )\n",
        "            self._transformer_layers.append(layer)\n",
        "\n",
        "        self.inputs = dict(\n",
        "            input_ids=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "            input_mask=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "            segment_ids=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if isinstance(inputs, dict):\n",
        "            input_ids = inputs.get(\"input_ids\")\n",
        "            input_mask = inputs.get(\"input_mask\")\n",
        "        else:\n",
        "            raise ValueError(f\"Inputs should be a dict. Received: {inputs}.\")\n",
        "\n",
        "        embeddings = self._token_and_position_embedding_layer(input_ids)\n",
        "        embeddings = self._embedding_norm_layer(embeddings)\n",
        "        embeddings = self._embedding_dropout(embeddings)\n",
        "\n",
        "        x = embeddings\n",
        "        for layer in self._transformer_layers:\n",
        "            x = layer(x, padding_mask=input_mask)\n",
        "        sequence_output = x\n",
        "        return sequence_output\n",
        "\n",
        "    def get_embedding_table(self):\n",
        "        return self._token_and_position_embedding_layer.token_embedding.embeddings\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_layers\": self.num_layers,\n",
        "                \"num_attention_heads\": self.num_attention_heads,\n",
        "                \"max_sequence_length\": self.max_sequence_length,\n",
        "                \"inner_size\": self.inner_size,\n",
        "                \"inner_activation\": keras.activations.serialize(\n",
        "                    self.inner_activation\n",
        "                ),\n",
        "                \"dropout\": self.dropout,\n",
        "                \"initializer_range\": self.initializer_range,\n",
        "            }\n",
        "        )\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RoBERTaModel(vocab_size=50265)\n",
        "model(dict(\n",
        "  input_ids=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "  input_mask=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "  segment_ids=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "))\n",
        "\n",
        "mlm_head = keras_nlp.layers.MLMHead(\n",
        "    vocabulary_size=50265,\n",
        "    embedding_weights=model.get_embedding_table(),\n",
        ")"
      ],
      "metadata": {
        "id": "oExEudYUkwwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlm_head.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtkz-e0x5_0Y",
        "outputId": "fce621d1-a058-4524-806b-ef43bd8a1bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'ro_ber_ta_model_2/token_and_position_embeddings/token_embedding2/embeddings:0' shape=(50265, 768) dtype=float32, numpy=\n",
              " array([[-0.00134202, -0.00773878,  0.00736229, ...,  0.00861523,\n",
              "          0.00948601, -0.00805972],\n",
              "        [-0.00815954,  0.00617338,  0.00717904, ...,  0.00723502,\n",
              "         -0.00207715,  0.00026414],\n",
              "        [-0.00254391,  0.00130945,  0.00356971, ..., -0.00068971,\n",
              "         -0.00576109, -0.0100769 ],\n",
              "        ...,\n",
              "        [ 0.00705787, -0.00680857,  0.00919869, ..., -0.01081331,\n",
              "         -0.00946475, -0.00179045],\n",
              "        [ 0.0077587 ,  0.00287509,  0.00430533, ...,  0.00194891,\n",
              "         -0.0082851 ,  0.00681807],\n",
              "        [-0.00688892,  0.00786575, -0.00903068, ...,  0.00690948,\n",
              "         -0.01009752, -0.00629842]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "-vW0-bolk-1r",
        "outputId": "fdd61890-f5de-43d3-81b5-a76c401a0995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load PyTorch Checkpoints"
      ],
      "metadata": {
        "id": "sdHWGuz8kxl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"drive/MyDrive/roberta.base/model.pt\", map_location=torch.device('cpu'))\n",
        "ckp = checkpoint['model'] # ckp used later\n",
        "ckp.keys()"
      ],
      "metadata": {
        "id": "LBM9fB5Xk3wZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f882c27-3c37-45ad-f863-7f4cd7b22a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "odict_keys(['decoder.sentence_encoder.embed_tokens.weight', 'decoder.sentence_encoder.embed_positions.weight', 'decoder.sentence_encoder.layers.0.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.0.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.0.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.0.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.0.fc1.weight', 'decoder.sentence_encoder.layers.0.fc1.bias', 'decoder.sentence_encoder.layers.0.fc2.weight', 'decoder.sentence_encoder.layers.0.fc2.bias', 'decoder.sentence_encoder.layers.0.final_layer_norm.weight', 'decoder.sentence_encoder.layers.0.final_layer_norm.bias', 'decoder.sentence_encoder.layers.1.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.1.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.1.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.1.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.1.fc1.weight', 'decoder.sentence_encoder.layers.1.fc1.bias', 'decoder.sentence_encoder.layers.1.fc2.weight', 'decoder.sentence_encoder.layers.1.fc2.bias', 'decoder.sentence_encoder.layers.1.final_layer_norm.weight', 'decoder.sentence_encoder.layers.1.final_layer_norm.bias', 'decoder.sentence_encoder.layers.2.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.2.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.2.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.2.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.2.fc1.weight', 'decoder.sentence_encoder.layers.2.fc1.bias', 'decoder.sentence_encoder.layers.2.fc2.weight', 'decoder.sentence_encoder.layers.2.fc2.bias', 'decoder.sentence_encoder.layers.2.final_layer_norm.weight', 'decoder.sentence_encoder.layers.2.final_layer_norm.bias', 'decoder.sentence_encoder.layers.3.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.3.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.3.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.3.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.3.fc1.weight', 'decoder.sentence_encoder.layers.3.fc1.bias', 'decoder.sentence_encoder.layers.3.fc2.weight', 'decoder.sentence_encoder.layers.3.fc2.bias', 'decoder.sentence_encoder.layers.3.final_layer_norm.weight', 'decoder.sentence_encoder.layers.3.final_layer_norm.bias', 'decoder.sentence_encoder.layers.4.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.4.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.4.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.4.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.4.fc1.weight', 'decoder.sentence_encoder.layers.4.fc1.bias', 'decoder.sentence_encoder.layers.4.fc2.weight', 'decoder.sentence_encoder.layers.4.fc2.bias', 'decoder.sentence_encoder.layers.4.final_layer_norm.weight', 'decoder.sentence_encoder.layers.4.final_layer_norm.bias', 'decoder.sentence_encoder.layers.5.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.5.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.5.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.5.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.5.fc1.weight', 'decoder.sentence_encoder.layers.5.fc1.bias', 'decoder.sentence_encoder.layers.5.fc2.weight', 'decoder.sentence_encoder.layers.5.fc2.bias', 'decoder.sentence_encoder.layers.5.final_layer_norm.weight', 'decoder.sentence_encoder.layers.5.final_layer_norm.bias', 'decoder.sentence_encoder.layers.6.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.6.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.6.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.6.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.6.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.6.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.6.fc1.weight', 'decoder.sentence_encoder.layers.6.fc1.bias', 'decoder.sentence_encoder.layers.6.fc2.weight', 'decoder.sentence_encoder.layers.6.fc2.bias', 'decoder.sentence_encoder.layers.6.final_layer_norm.weight', 'decoder.sentence_encoder.layers.6.final_layer_norm.bias', 'decoder.sentence_encoder.layers.7.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.7.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.7.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.7.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.7.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.7.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.7.fc1.weight', 'decoder.sentence_encoder.layers.7.fc1.bias', 'decoder.sentence_encoder.layers.7.fc2.weight', 'decoder.sentence_encoder.layers.7.fc2.bias', 'decoder.sentence_encoder.layers.7.final_layer_norm.weight', 'decoder.sentence_encoder.layers.7.final_layer_norm.bias', 'decoder.sentence_encoder.layers.8.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.8.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.8.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.8.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.8.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.8.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.8.fc1.weight', 'decoder.sentence_encoder.layers.8.fc1.bias', 'decoder.sentence_encoder.layers.8.fc2.weight', 'decoder.sentence_encoder.layers.8.fc2.bias', 'decoder.sentence_encoder.layers.8.final_layer_norm.weight', 'decoder.sentence_encoder.layers.8.final_layer_norm.bias', 'decoder.sentence_encoder.layers.9.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.9.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.9.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.9.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.9.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.9.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.9.fc1.weight', 'decoder.sentence_encoder.layers.9.fc1.bias', 'decoder.sentence_encoder.layers.9.fc2.weight', 'decoder.sentence_encoder.layers.9.fc2.bias', 'decoder.sentence_encoder.layers.9.final_layer_norm.weight', 'decoder.sentence_encoder.layers.9.final_layer_norm.bias', 'decoder.sentence_encoder.layers.10.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.10.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.10.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.10.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.10.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.10.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.10.fc1.weight', 'decoder.sentence_encoder.layers.10.fc1.bias', 'decoder.sentence_encoder.layers.10.fc2.weight', 'decoder.sentence_encoder.layers.10.fc2.bias', 'decoder.sentence_encoder.layers.10.final_layer_norm.weight', 'decoder.sentence_encoder.layers.10.final_layer_norm.bias', 'decoder.sentence_encoder.layers.11.self_attn.in_proj_weight', 'decoder.sentence_encoder.layers.11.self_attn.in_proj_bias', 'decoder.sentence_encoder.layers.11.self_attn.out_proj.weight', 'decoder.sentence_encoder.layers.11.self_attn.out_proj.bias', 'decoder.sentence_encoder.layers.11.self_attn_layer_norm.weight', 'decoder.sentence_encoder.layers.11.self_attn_layer_norm.bias', 'decoder.sentence_encoder.layers.11.fc1.weight', 'decoder.sentence_encoder.layers.11.fc1.bias', 'decoder.sentence_encoder.layers.11.fc2.weight', 'decoder.sentence_encoder.layers.11.fc2.bias', 'decoder.sentence_encoder.layers.11.final_layer_norm.weight', 'decoder.sentence_encoder.layers.11.final_layer_norm.bias', 'decoder.sentence_encoder.emb_layer_norm.weight', 'decoder.sentence_encoder.emb_layer_norm.bias', 'decoder.lm_head.weight', 'decoder.lm_head.bias', 'decoder.lm_head.dense.weight', 'decoder.lm_head.dense.bias', 'decoder.lm_head.layer_norm.weight', 'decoder.lm_head.layer_norm.bias'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckp['decoder.lm_head.weight'].shape, ckp['decoder.lm_head.bias'].shape, ckp['decoder.lm_head.dense.weight'].shape, ckp['decoder.lm_head.dense.bias'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go_ou8XE5ERE",
        "outputId": "fbf01eef-d775-48a8-e3a3-e8bd798967ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([50265, 768]),\n",
              " torch.Size([50265]),\n",
              " torch.Size([768, 768]),\n",
              " torch.Size([768]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S1SPv0YN5knM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get TF RoBERTa layers\n"
      ],
      "metadata": {
        "id": "iZz0xtDzmhXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer2name = dict()\n",
        "layer2shape = dict()\n",
        "for layer in model.layers:\n",
        "  layer2name[layer] = list(map(lambda x: x.name, layer.weights))\n",
        "  layer2shape[layer] = list(map(lambda x: x.shape, layer.weights))\n",
        "layer2name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e59f_eMamJAy",
        "outputId": "ba71236a-fbc8-400e-f38e-242f976d973a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{<keras.layers.core.dropout.Dropout at 0x7efc17895910>: [],\n",
              " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x7efc17895650>: ['ro_ber_ta_model_1/embeddings/layer_norm/gamma:0',\n",
              "  'ro_ber_ta_model_1/embeddings/layer_norm/beta:0'],\n",
              " <keras_nlp.layers.token_and_position_embedding.TokenAndPositionEmbedding at 0x7efc17887fd0>: ['ro_ber_ta_model_1/token_and_position_embeddings/token_embedding2/embeddings:0',\n",
              "  'ro_ber_ta_model_1/token_and_position_embeddings/position_embedding2/embeddings:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17872c10>: ['ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/multi_head_attention_10/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/layer_normalization_20/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/layer_normalization_20/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/layer_normalization_21/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/layer_normalization_21/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/dense_20/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/dense_20/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/dense_21/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_10/dense_21/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17872d90>: ['ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/multi_head_attention_8/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/layer_normalization_16/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/layer_normalization_16/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/layer_normalization_17/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/layer_normalization_17/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/dense_16/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/dense_16/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/dense_17/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_8/dense_17/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc1787bd50>: ['ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/multi_head_attention_7/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/layer_normalization_14/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/layer_normalization_14/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/layer_normalization_15/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/layer_normalization_15/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/dense_14/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/dense_14/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/dense_15/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_7/dense_15/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17895bd0>: ['ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/multi_head_attention/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/layer_normalization/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/layer_normalization/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/layer_normalization_1/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/layer_normalization_1/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/dense/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/dense/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/dense_1/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_0/dense_1/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17896150>: ['ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/multi_head_attention_6/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/layer_normalization_12/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/layer_normalization_12/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/layer_normalization_13/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/layer_normalization_13/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/dense_12/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/dense_12/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/dense_13/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_6/dense_13/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178967d0>: ['ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/multi_head_attention_11/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/layer_normalization_22/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/layer_normalization_22/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/layer_normalization_23/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/layer_normalization_23/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/dense_22/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/dense_22/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/dense_23/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_11/dense_23/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa1d0>: ['ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/multi_head_attention_1/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/layer_normalization_2/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/layer_normalization_2/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/layer_normalization_3/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/layer_normalization_3/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/dense_2/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/dense_2/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/dense_3/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_1/dense_3/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa2d0>: ['ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/multi_head_attention_2/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/layer_normalization_4/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/layer_normalization_4/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/layer_normalization_5/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/layer_normalization_5/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/dense_4/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/dense_4/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/dense_5/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_2/dense_5/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa650>: ['ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/multi_head_attention_3/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/layer_normalization_6/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/layer_normalization_6/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/layer_normalization_7/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/layer_normalization_7/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/dense_6/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/dense_6/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/dense_7/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_3/dense_7/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa9d0>: ['ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/multi_head_attention_5/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/layer_normalization_10/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/layer_normalization_10/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/layer_normalization_11/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/layer_normalization_11/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/dense_10/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/dense_10/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/dense_11/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_5/dense_11/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aad10>: ['ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/multi_head_attention_4/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/layer_normalization_8/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/layer_normalization_8/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/layer_normalization_9/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/layer_normalization_9/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/dense_8/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/dense_8/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/dense_9/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_4/dense_9/bias:0'],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aae10>: ['ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/query/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/query/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/key/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/key/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/value/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/value/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/attention_output/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/multi_head_attention_9/attention_output/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/layer_normalization_18/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/layer_normalization_18/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/layer_normalization_19/gamma:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/layer_normalization_19/beta:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/dense_18/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/dense_18/bias:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/dense_19/kernel:0',\n",
              "  'ro_ber_ta_model_1/transformer/layer_9/dense_19/bias:0']}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer2shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC6LzmumpTfc",
        "outputId": "f6ae69b5-a84d-4313-f1c2-f6bc0f5da889"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{<keras.layers.core.dropout.Dropout at 0x7efc17895910>: [],\n",
              " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x7efc17895650>: [TensorShape([768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.token_and_position_embedding.TokenAndPositionEmbedding at 0x7efc17887fd0>: [TensorShape([50265, 768]),\n",
              "  TensorShape([512, 768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17872c10>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17872d90>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc1787bd50>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17895bd0>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17896150>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178967d0>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa1d0>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa2d0>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa650>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa9d0>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aad10>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])],\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aae10>: [TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([768, 12, 64]),\n",
              "  TensorShape([12, 64]),\n",
              "  TensorShape([12, 64, 768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768]),\n",
              "  TensorShape([768, 3072]),\n",
              "  TensorShape([3072]),\n",
              "  TensorShape([3072, 768]),\n",
              "  TensorShape([768])]}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9-dvxDlo8zx",
        "outputId": "0846b2b9-590f-4a8a-a77c-ec3bfb3531c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras_nlp.layers.token_and_position_embedding.TokenAndPositionEmbedding at 0x7efc17887fd0>,\n",
              " <keras.layers.normalization.layer_normalization.LayerNormalization at 0x7efc17895650>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7efc17895910>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17895bd0>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa1d0>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa2d0>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa650>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aad10>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aa9d0>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17896150>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc1787bd50>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17872d90>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178aae10>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc17872c10>,\n",
              " <keras_nlp.layers.transformer_encoder.TransformerEncoder at 0x7efc178967d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert PyTorch Tensor to TF Tensor"
      ],
      "metadata": {
        "id": "6AdL6YUxoiNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Layers"
      ],
      "metadata": {
        "id": "Z41cXXghoqhr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenandpositionembedding_layer = model.layers[0] #TokenAndPositionEmbedding"
      ],
      "metadata": {
        "id": "kIL14I6Nmf5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_tensor = ckp['decoder.sentence_encoder.embed_tokens.weight'].numpy()\n",
        "position_tensor = ckp['decoder.sentence_encoder.embed_positions.weight'].numpy()[2:, :]\n",
        "embedding_tensor.shape, position_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReCM1NnPpHXT",
        "outputId": "bf62224f-1d0c-4cb9-d33a-dee6220dafdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50265, 768), (512, 768))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenandpositionembedding_layer.set_weights([embedding_tensor, position_tensor])"
      ],
      "metadata": {
        "id": "YYBfFvENp_qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layernorm = model.layers[1]"
      ],
      "metadata": {
        "id": "t_dbof8Rqc2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma_tensor = ckp['decoder.sentence_encoder.emb_layer_norm.weight']\n",
        "beta_tensor = ckp['decoder.sentence_encoder.emb_layer_norm.bias']"
      ],
      "metadata": {
        "id": "1ARlu32uqnS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layernorm.set_weights([gamma_tensor, beta_tensor])"
      ],
      "metadata": {
        "id": "m8bewxJWq8VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Layers"
      ],
      "metadata": {
        "id": "r7oUH5UhqUvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "  transformer_layer = model.layers[i+3]\n",
        "\n",
        "  size = 768\n",
        "  # query\n",
        "  query_weights = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.in_proj_weight'].numpy()\n",
        "  query_weights = (query_weights.T)[:, :size].reshape(768, 12, 64)\n",
        "  query_bias = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.in_proj_bias'].numpy()\n",
        "  query_bias = query_bias[:size].reshape(12, 64)\n",
        "  # key\n",
        "  key_weights = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.in_proj_weight'].numpy()\n",
        "  key_weights = (key_weights.T)[:, size:size*2].reshape(768, 12, 64)\n",
        "  key_bias = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.in_proj_bias'].numpy()\n",
        "  key_bias = key_bias[size:size*2].reshape(12, 64)\n",
        "  # value\n",
        "  value_weights = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.in_proj_weight'].numpy()\n",
        "  value_weights = (value_weights.T)[:, size*2:size*3].reshape(768, 12, 64)\n",
        "  value_bias = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.in_proj_bias'].numpy()\n",
        "  value_bias = value_bias[size*2:size*3].reshape(12, 64)\n",
        "  # attention output\n",
        "  attention_weight = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.out_proj.weight'].numpy()\n",
        "  attention_weight = attention_weight.T.reshape(12, 64, 768)\n",
        "  attention_bias = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn.out_proj.bias'].numpy()\n",
        "  # layer norms\n",
        "  layernorm_1_gamma = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn_layer_norm.weight'].numpy()\n",
        "  layernorm_1_beta = ckp[f'decoder.sentence_encoder.layers.{i}.self_attn_layer_norm.bias'].numpy()\n",
        "  layernorm_2_gamma = ckp[f'decoder.sentence_encoder.layers.{i}.final_layer_norm.weight'].numpy()\n",
        "  layernorm_2_beta = ckp[f'decoder.sentence_encoder.layers.{i}.final_layer_norm.bias'].numpy()\n",
        "  # dense\n",
        "  dense_1_weight = ckp[f'decoder.sentence_encoder.layers.{i}.fc1.weight'].numpy().T\n",
        "  dense_1_bias = ckp[f'decoder.sentence_encoder.layers.{i}.fc1.bias'].numpy()\n",
        "  dense_2_weight = ckp[f'decoder.sentence_encoder.layers.{i}.fc2.weight'].numpy().T\n",
        "  dense_2_bias = ckp[f'decoder.sentence_encoder.layers.{i}.fc2.bias'].numpy()\n",
        "\n",
        "  weights = [\n",
        "      query_weights, query_bias, key_weights, key_bias, value_weights, value_bias,\n",
        "      attention_weight, attention_bias, \n",
        "      layernorm_1_gamma, layernorm_1_beta, layernorm_2_gamma, layernorm_2_beta,\n",
        "      dense_1_weight, dense_1_bias, dense_2_weight, dense_2_bias\n",
        "  ]\n",
        "\n",
        "  transformer_layer.set_weights(weights)"
      ],
      "metadata": {
        "id": "kCT1BeyNqXE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('drive/MyDrive/tf_roberta_ckp_2')"
      ],
      "metadata": {
        "id": "2DWr1FnS7sj9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}