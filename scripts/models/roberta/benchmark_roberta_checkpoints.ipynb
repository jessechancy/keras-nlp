{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BenchmarkRoBERTaCheckpoint.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4299f4a002b4691bc93331b01c6a94e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a17fb527f1c4bb7ba5586eed9dae4a7",
              "IPY_MODEL_2bf65c306c784d9a9da3e33d5a7f9555",
              "IPY_MODEL_b30e051ff322405eb8d8f055f4c34fa7"
            ],
            "layout": "IPY_MODEL_c67857d3239147b5964aa3a9b11e99e6"
          }
        },
        "5a17fb527f1c4bb7ba5586eed9dae4a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4284b354c0d345c89b146021c0e4d6ec",
            "placeholder": "​",
            "style": "IPY_MODEL_51fdd39ee4f44252b1e56e8585b084af",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "2bf65c306c784d9a9da3e33d5a7f9555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65c95b65da344485ae34a48e9b3f5b99",
            "max": 501200538,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e66a6a0c55e42bf91467cb1ca88a5ba",
            "value": 501200538
          }
        },
        "b30e051ff322405eb8d8f055f4c34fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7661c0dd77a4257828ba0ca99776747",
            "placeholder": "​",
            "style": "IPY_MODEL_d0a5f70fdefa4baaa4a10c09c959b638",
            "value": " 478M/478M [00:23&lt;00:00, 29.6MB/s]"
          }
        },
        "c67857d3239147b5964aa3a9b11e99e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4284b354c0d345c89b146021c0e4d6ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51fdd39ee4f44252b1e56e8585b084af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65c95b65da344485ae34a48e9b3f5b99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e66a6a0c55e42bf91467cb1ca88a5ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7661c0dd77a4257828ba0ca99776747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0a5f70fdefa4baaa4a10c09c959b638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Benchmarking Fairseq Checkpoint Converted RoBERTa with Huggingface RoBERTa\n"
      ],
      "metadata": {
        "id": "yURGBQczyTUg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "dwgsShBYxihu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5Nj6K26yRpO",
        "outputId": "e7805894-426c-4d1d-e673-c9c9398726ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.7 MB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 101 kB 8.1 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJzDjgF-xUNw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_nlp\n",
        "from transformers import RobertaTokenizer, RobertaModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Replace me by any text you'd like.\""
      ],
      "metadata": {
        "id": "lA12EOnJ3ih-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load HuggingFace transformer"
      ],
      "metadata": {
        "id": "gHR1A4xKynY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaModel.from_pretrained('roberta-base')\n",
        "# encoded_input = tokenizer(text, return_tensors='tf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "e4299f4a002b4691bc93331b01c6a94e",
            "5a17fb527f1c4bb7ba5586eed9dae4a7",
            "2bf65c306c784d9a9da3e33d5a7f9555",
            "b30e051ff322405eb8d8f055f4c34fa7",
            "c67857d3239147b5964aa3a9b11e99e6",
            "4284b354c0d345c89b146021c0e4d6ec",
            "51fdd39ee4f44252b1e56e8585b084af",
            "65c95b65da344485ae34a48e9b3f5b99",
            "7e66a6a0c55e42bf91467cb1ca88a5ba",
            "a7661c0dd77a4257828ba0ca99776747",
            "d0a5f70fdefa4baaa4a10c09c959b638"
          ]
        },
        "id": "SqfxWVoE1fCV",
        "outputId": "27c361a6-114f-4e30-8b5e-d8a4350c6182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/478M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4299f4a002b4691bc93331b01c6a94e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsFFfvcJfghz",
        "outputId": "59cb939c-31aa-48d6-efac-1ddd10d6cdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RobertaModel(\n",
            "  (embeddings): RobertaEmbeddings(\n",
            "    (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
            "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "    (token_type_embeddings): Embedding(1, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): RobertaEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): RobertaLayer(\n",
            "        (attention): RobertaAttention(\n",
            "          (self): RobertaSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): RobertaSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): RobertaIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): RobertaOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): RobertaPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHxzgPYffZa7",
        "outputId": "bba313d9-2d08-4c4e-edd0-14c244611b5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_roberta_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " roberta (TFRobertaMainLayer  multiple                 124645632 \n",
            " )                                                               \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,645,632\n",
            "Trainable params: 124,645,632\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(encoded_input)\n",
        "lhs = output['last_hidden_state']\n",
        "output\n"
      ],
      "metadata": {
        "id": "zV2d7Quy3nei",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eab7de4-4c8d-4941-a9f1-1a5bc73c13cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPoolingAndCrossAttentions([('last_hidden_state',\n",
              "                                                 <tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
              "                                                 array([[[-0.11464322,  0.11033366, -0.01485661, ..., -0.08089949,\n",
              "                                                          -0.00180671, -0.02707539],\n",
              "                                                         [-0.02248321,  0.16116916,  0.05555495, ...,  0.536597  ,\n",
              "                                                           0.11962057,  0.1575807 ],\n",
              "                                                         [ 0.05315709, -0.00201554,  0.03704416, ..., -0.4886861 ,\n",
              "                                                           0.16412729,  0.2736186 ],\n",
              "                                                         ...,\n",
              "                                                         [-0.1585741 ,  0.0837442 ,  0.1301794 , ...,  0.3970098 ,\n",
              "                                                           0.17148302, -0.08482045],\n",
              "                                                         [-0.10652635,  0.10436887, -0.03831968, ..., -0.10680682,\n",
              "                                                          -0.00145994, -0.05167906],\n",
              "                                                         [ 0.00592946,  0.07583928,  0.12279624, ...,  0.10374899,\n",
              "                                                           0.00748081,  0.09762435]]], dtype=float32)>),\n",
              "                                                ('pooler_output',\n",
              "                                                 <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              "                                                 array([[-2.83462461e-03, -1.88498855e-01, -2.14611158e-01,\n",
              "                                                         -1.15304723e-01,  1.31887034e-01,  2.35393927e-01,\n",
              "                                                          2.71589637e-01, -6.08555339e-02, -8.37083608e-02,\n",
              "                                                         -1.92976326e-01,  2.65645444e-01, -4.34159010e-05,\n",
              "                                                         -1.12001158e-01,  1.46364316e-01, -1.45022124e-01,\n",
              "                                                          4.93904948e-01,  2.03168944e-01, -5.30506253e-01,\n",
              "                                                          7.56741986e-02, -3.77842337e-02, -2.87061721e-01,\n",
              "                                                          7.91154355e-02,  4.94977146e-01,  3.66258949e-01,\n",
              "                                                          1.07554689e-01,  4.57071699e-02, -1.58037499e-01,\n",
              "                                                          1.33375879e-02,  1.54704675e-01,  2.64108688e-01,\n",
              "                                                          3.04253429e-01,  3.55271511e-02,  1.13974869e-01,\n",
              "                                                          2.59316176e-01, -2.54771203e-01,  6.68199062e-02,\n",
              "                                                         -3.40113789e-01,  8.43658298e-03,  2.89693415e-01,\n",
              "                                                         -1.92514792e-01, -8.17954615e-02,  1.79970503e-01,\n",
              "                                                          1.94201738e-01, -1.87201202e-01, -1.08354919e-01,\n",
              "                                                          4.26602393e-01,  2.52899319e-01,  4.40491512e-02,\n",
              "                                                         -1.58766210e-01, -9.27073285e-02, -3.33070695e-01,\n",
              "                                                          3.72656107e-01,  3.01957935e-01,  2.23973364e-01,\n",
              "                                                         -6.32874891e-02,  4.36989889e-02, -9.30486172e-02,\n",
              "                                                          2.83647507e-01, -7.58509785e-02, -7.66498670e-02,\n",
              "                                                         -1.24425471e-01, -2.33568087e-01,  7.31399842e-03,\n",
              "                                                         -6.63880557e-02,  4.79605459e-02, -1.39588252e-01,\n",
              "                                                          1.07330866e-01, -1.60853922e-01, -1.35634780e-01,\n",
              "                                                          3.11963484e-02, -1.13000207e-01,  1.70037001e-01,\n",
              "                                                          1.69642225e-01, -3.33129346e-01, -3.11024725e-01,\n",
              "                                                          7.02773184e-02, -6.34573579e-01, -9.61445123e-02,\n",
              "                                                          3.44681025e-01,  4.64234859e-01, -8.32553953e-02,\n",
              "                                                          2.40881488e-01,  3.90450247e-02,  2.16559023e-01,\n",
              "                                                         -1.28064435e-02, -7.33433217e-02, -4.68510203e-02,\n",
              "                                                         -1.43731907e-01,  1.41004950e-01,  2.64732897e-01,\n",
              "                                                         -2.14258894e-01, -4.62402076e-01,  4.32158373e-02,\n",
              "                                                          3.91334370e-02, -9.23475400e-02,  2.22543739e-02,\n",
              "                                                         -1.13723064e-02, -1.11266606e-01, -1.84714928e-01,\n",
              "                                                         -1.80381745e-01,  9.90886316e-02, -2.42777318e-01,\n",
              "                                                         -1.51521713e-01,  2.65727580e-01,  4.73842403e-04,\n",
              "                                                         -1.63552582e-01,  8.23855225e-04,  3.20382118e-01,\n",
              "                                                          5.03214635e-02, -1.00961447e-01, -2.11417198e-01,\n",
              "                                                          4.71461415e-01,  3.53900850e-01, -3.49468961e-02,\n",
              "                                                         -1.26485585e-03,  1.76740706e-01,  1.50857449e-01,\n",
              "                                                         -2.91371793e-01,  4.58072245e-01, -3.33002776e-01,\n",
              "                                                         -3.98669671e-03, -1.04643531e-01,  1.44639090e-01,\n",
              "                                                          1.91781536e-01, -2.08232820e-01,  3.04694086e-01,\n",
              "                                                          1.51752755e-01,  3.09445262e-01,  2.11455226e-01,\n",
              "                                                          1.41624272e-01, -4.42611426e-02,  1.36408806e-01,\n",
              "                                                         -1.39448240e-01,  1.59545273e-01,  2.38723934e-01,\n",
              "                                                          1.20402321e-01, -4.96092020e-03, -3.41121048e-01,\n",
              "                                                         -2.60196775e-01,  3.09654295e-01,  3.43744010e-01,\n",
              "                                                          1.32894561e-01, -6.32428750e-02,  2.02330872e-01,\n",
              "                                                          1.04698017e-01,  2.47542858e-01,  1.47364035e-01,\n",
              "                                                         -4.45110083e-01,  4.23475467e-02,  3.58708888e-01,\n",
              "                                                          1.22129112e-01,  1.57138065e-01, -1.15785353e-01,\n",
              "                                                         -3.08718085e-01, -2.81168729e-01, -1.10939145e-01,\n",
              "                                                          5.69358431e-02, -3.60701263e-01, -1.22760601e-01,\n",
              "                                                          3.90222400e-01,  8.41300040e-02, -7.20163137e-02,\n",
              "                                                         -1.98392063e-01, -2.20411226e-01, -1.12394057e-02,\n",
              "                                                         -1.23891197e-01,  6.90232730e-03,  9.83171239e-02,\n",
              "                                                         -7.98659101e-02, -4.67902184e-01, -1.36348054e-01,\n",
              "                                                         -5.35108149e-01, -9.69467238e-02,  2.20630839e-01,\n",
              "                                                         -3.55469316e-01,  3.07912081e-01, -2.94229686e-01,\n",
              "                                                          1.05398484e-01,  4.13357913e-01,  5.99129125e-02,\n",
              "                                                         -1.85414907e-02, -2.40882531e-01, -1.63688529e-02,\n",
              "                                                          9.35609341e-02,  3.25142413e-01,  2.97565818e-01,\n",
              "                                                         -4.35692966e-01,  1.07735246e-01,  1.43018007e-01,\n",
              "                                                          3.16046238e-01,  1.10535651e-01, -8.92986059e-02,\n",
              "                                                         -1.19407997e-01,  1.74820065e-01, -2.18875006e-01,\n",
              "                                                          1.78487971e-01, -2.29322836e-01,  2.06468731e-01,\n",
              "                                                         -2.59875298e-01, -2.58964866e-01,  3.15792322e-01,\n",
              "                                                         -4.53481913e-01, -7.65716061e-02,  8.15460160e-02,\n",
              "                                                          2.54536033e-01,  6.58381218e-03, -5.58899716e-02,\n",
              "                                                         -1.01947062e-01,  1.85800329e-01,  1.75863370e-01,\n",
              "                                                          1.20089971e-01, -4.25801754e-01,  3.18333328e-01,\n",
              "                                                         -3.52253839e-02, -3.67167145e-02, -3.64684165e-02,\n",
              "                                                          1.86299056e-01,  2.55718201e-01,  9.97016802e-02,\n",
              "                                                         -3.85841548e-01, -1.56457171e-01,  1.35894522e-01,\n",
              "                                                          3.14581156e-01, -2.66971350e-01,  1.66928604e-01,\n",
              "                                                         -3.33158702e-01, -4.36996520e-01, -1.10806905e-01,\n",
              "                                                          2.48614416e-01,  2.24930882e-01,  1.99452028e-01,\n",
              "                                                         -3.02256793e-01,  1.74102560e-01, -1.56818256e-01,\n",
              "                                                         -4.58907306e-01, -3.88764769e-01, -1.36551589e-01,\n",
              "                                                          2.39691794e-01,  1.79826140e-01,  1.68945476e-01,\n",
              "                                                          2.57151514e-01,  3.07514053e-02,  1.12780519e-01,\n",
              "                                                          1.63555831e-01,  1.61395639e-01, -1.32349387e-01,\n",
              "                                                          1.56063467e-01, -3.68840903e-01, -4.38596345e-02,\n",
              "                                                         -3.29115808e-01, -2.10126325e-01, -2.26527825e-01,\n",
              "                                                          4.25789833e-01, -2.57973641e-01,  2.64232755e-01,\n",
              "                                                          4.35907573e-01, -3.39863390e-01, -1.07836217e-01,\n",
              "                                                          1.48095757e-01,  1.87711075e-01,  5.87924495e-02,\n",
              "                                                         -9.36270729e-02,  2.09702805e-01,  2.06223607e-01,\n",
              "                                                         -1.05145358e-01,  2.82386035e-01, -4.39755172e-02,\n",
              "                                                          2.96931893e-01,  1.50878832e-01,  4.68620174e-02,\n",
              "                                                          1.69962555e-01,  1.35661691e-01, -1.30445868e-01,\n",
              "                                                          8.14601555e-02,  1.26639064e-02, -3.34642492e-02,\n",
              "                                                         -2.89862335e-01, -1.42296746e-01,  2.38943234e-01,\n",
              "                                                         -7.37021714e-02,  2.36933827e-02, -1.67920589e-01,\n",
              "                                                         -2.92382687e-02,  1.13198254e-02,  4.26762849e-01,\n",
              "                                                         -3.71551663e-01,  2.77337790e-01,  5.95522225e-02,\n",
              "                                                          1.48427501e-01, -2.37171561e-01, -2.41737321e-01,\n",
              "                                                          1.21265881e-01,  2.34050289e-01, -4.71625566e-01,\n",
              "                                                          4.46625799e-02,  1.17256910e-01,  9.07087475e-02,\n",
              "                                                          2.17854902e-01,  2.84666806e-01,  4.36959701e-04,\n",
              "                                                         -1.14906147e-01,  5.66531301e-01, -1.53763101e-01,\n",
              "                                                         -1.34484395e-01,  2.67691344e-01, -3.00394356e-01,\n",
              "                                                         -3.00434589e-01,  2.73986965e-01, -1.97565239e-02,\n",
              "                                                          3.19117188e-01,  1.46217838e-01,  5.66066243e-02,\n",
              "                                                          6.16165139e-02, -6.18167818e-01,  8.02403986e-02,\n",
              "                                                         -4.81217951e-01, -1.55916922e-02,  5.35474420e-02,\n",
              "                                                         -8.44739005e-02, -2.32826516e-01,  1.60899997e-01,\n",
              "                                                          3.18688005e-01, -2.30778456e-01, -1.91767644e-02,\n",
              "                                                          2.18904853e-01,  4.88857925e-02, -1.20043233e-01,\n",
              "                                                          4.83282924e-01, -1.87559682e-03,  2.26317167e-01,\n",
              "                                                         -5.11159785e-02,  2.39013374e-01, -2.31458098e-01,\n",
              "                                                          2.69827992e-01, -2.91262746e-01, -1.20032720e-01,\n",
              "                                                          6.24546856e-02,  7.88692459e-02,  4.19797041e-02,\n",
              "                                                         -7.51157254e-02, -3.91759008e-01,  2.56785065e-01,\n",
              "                                                         -1.13816690e-02, -7.37754628e-02, -5.68236858e-02,\n",
              "                                                          1.08980760e-01, -2.58170068e-02,  7.33283237e-02,\n",
              "                                                          8.82735401e-02,  3.66677701e-01,  2.45587170e-01,\n",
              "                                                         -1.24926539e-02, -4.14099038e-01, -8.95741358e-02,\n",
              "                                                         -1.24731481e-01,  7.02693313e-02,  6.04757108e-02,\n",
              "                                                          1.41082276e-02,  4.87325221e-01, -7.12454766e-02,\n",
              "                                                          2.60756873e-02, -1.50837019e-01,  2.89140791e-01,\n",
              "                                                          2.23435000e-01,  1.75639108e-01,  1.63651600e-01,\n",
              "                                                          5.47862947e-02,  1.80400491e-01, -4.71305251e-02,\n",
              "                                                         -1.89314261e-02, -1.52031496e-01, -2.54575700e-01,\n",
              "                                                         -2.94428915e-01,  2.33361185e-01, -2.55137444e-01,\n",
              "                                                         -1.68705553e-01,  1.60141438e-01,  2.07685634e-01,\n",
              "                                                         -1.61115006e-01,  1.81652248e-01,  3.41957986e-01,\n",
              "                                                          1.52206391e-01, -1.65568486e-01,  3.17999005e-01,\n",
              "                                                         -7.68285394e-02,  6.50351569e-02,  3.01267296e-01,\n",
              "                                                         -8.36768672e-02,  2.05365703e-01,  5.44900835e-01,\n",
              "                                                          2.50540197e-01, -4.26706314e-01, -5.83510213e-02,\n",
              "                                                         -2.27323949e-01,  1.44753689e-02,  2.75062442e-01,\n",
              "                                                         -1.23888455e-01,  2.10659847e-01,  3.80465537e-01,\n",
              "                                                          3.09917033e-01,  4.93571639e-01, -1.54824471e-02,\n",
              "                                                         -1.14533015e-01,  1.19324170e-01,  2.37380728e-01,\n",
              "                                                          2.38089934e-02, -2.06679001e-01, -1.74903557e-01,\n",
              "                                                          3.00543934e-01,  9.50403735e-02, -1.64476871e-01,\n",
              "                                                          8.20316747e-03, -1.62509128e-01,  4.50582318e-02,\n",
              "                                                         -1.61213294e-01, -4.28708076e-01,  4.40343767e-02,\n",
              "                                                          1.67460874e-01, -5.08840084e-01,  1.26170561e-01,\n",
              "                                                         -3.16985309e-01,  3.66254449e-02, -2.46393353e-01,\n",
              "                                                          2.68727183e-01, -2.57273555e-01, -1.48966745e-01,\n",
              "                                                          4.35294896e-01, -5.58640212e-02,  2.71849744e-02,\n",
              "                                                         -1.94073543e-01, -1.61142275e-01,  2.91909296e-02,\n",
              "                                                         -1.65266509e-03, -7.26016164e-02, -4.96913493e-03,\n",
              "                                                          3.55023891e-01, -1.48244634e-01,  7.05995038e-02,\n",
              "                                                          2.85130739e-02,  2.14690879e-01, -7.35738501e-02,\n",
              "                                                          1.70184836e-01, -2.60294229e-03, -1.46418855e-01,\n",
              "                                                         -4.14916307e-01,  1.65213704e-01, -2.24692598e-01,\n",
              "                                                         -4.29761022e-01, -4.21133816e-01,  4.14868504e-01,\n",
              "                                                         -1.72898576e-01, -2.88105458e-01, -2.21525565e-01,\n",
              "                                                         -2.51112491e-01,  5.35292290e-02,  2.40498528e-01,\n",
              "                                                          4.72896338e-01, -4.00374413e-01, -5.92985749e-02,\n",
              "                                                          4.91828799e-01, -5.96236400e-02, -2.30989441e-01,\n",
              "                                                          2.76140451e-01,  2.08068639e-01, -3.25297028e-01,\n",
              "                                                          3.72580737e-01,  2.66731501e-01, -6.31062686e-02,\n",
              "                                                          5.17163910e-02,  5.42890251e-01,  1.18928336e-01,\n",
              "                                                          2.15985939e-01, -2.12273926e-01,  4.77601022e-01,\n",
              "                                                         -2.68592358e-01,  3.22618127e-01, -1.70617089e-01,\n",
              "                                                         -1.97707385e-01, -2.42150307e-01, -3.19615714e-02,\n",
              "                                                          3.61251175e-01,  1.93586588e-01, -4.58940297e-01,\n",
              "                                                         -1.31997883e-01,  4.30029221e-02,  3.31261575e-01,\n",
              "                                                         -4.21448916e-01, -6.01097867e-02,  4.09999788e-02,\n",
              "                                                         -3.64220977e-01,  1.25884518e-01,  1.38537019e-01,\n",
              "                                                          2.48973295e-01, -4.22427148e-01, -6.76975548e-02,\n",
              "                                                          4.11204875e-01, -3.44830513e-01,  1.38961285e-01,\n",
              "                                                          3.04094642e-01,  8.29779059e-02,  3.66096228e-01,\n",
              "                                                         -6.53098971e-02, -8.27954244e-03,  5.01486585e-02,\n",
              "                                                         -2.60107458e-01, -2.24350039e-02,  1.27166480e-01,\n",
              "                                                          5.84938645e-01,  1.44871533e-01, -4.03537631e-01,\n",
              "                                                          1.10674448e-01,  2.66532719e-01, -1.86594248e-01,\n",
              "                                                          3.39724869e-01, -1.05665602e-01, -3.79173569e-02,\n",
              "                                                          2.67966837e-01, -5.28822467e-02,  1.68602660e-01,\n",
              "                                                         -9.77739692e-02, -2.37145007e-01, -3.55620116e-01,\n",
              "                                                          4.17020768e-01, -1.99613675e-01, -1.13641769e-01,\n",
              "                                                         -2.03530118e-01, -1.09136291e-01, -1.93041652e-01,\n",
              "                                                          9.55454726e-03, -3.93960476e-01,  3.65188777e-01,\n",
              "                                                          1.39932901e-01, -2.18085274e-01, -9.80511457e-02,\n",
              "                                                         -1.09186836e-01, -2.05467269e-01, -2.02659458e-01,\n",
              "                                                         -2.93783426e-01,  4.29269582e-01, -1.89532876e-01,\n",
              "                                                         -4.95672554e-01,  2.42988661e-01, -1.30425608e-02,\n",
              "                                                          3.67999256e-01,  4.07446036e-03,  1.04806833e-01,\n",
              "                                                         -6.79642633e-02,  1.28748134e-01,  8.98626372e-02,\n",
              "                                                         -8.79735127e-02,  2.82493144e-01,  9.11689177e-02,\n",
              "                                                         -5.93729436e-01, -1.31066889e-01, -2.68109292e-01,\n",
              "                                                          9.85349640e-02,  2.34642014e-01, -3.96139443e-01,\n",
              "                                                          1.56557448e-02,  3.67240719e-02,  2.01533377e-01,\n",
              "                                                          1.13749597e-02, -1.21735036e-01, -7.08747506e-02,\n",
              "                                                          4.31486785e-01,  2.68587679e-01,  3.04361105e-01,\n",
              "                                                          1.33075774e-01,  2.31062397e-01, -4.51652566e-03,\n",
              "                                                         -3.62473428e-01,  1.80614106e-02,  9.49148089e-02,\n",
              "                                                         -1.98195606e-01,  4.69761640e-01, -1.22770801e-01,\n",
              "                                                         -3.90469640e-01, -7.13229105e-02,  4.24967945e-01,\n",
              "                                                          9.70547199e-02, -2.65541654e-02, -3.30669172e-02,\n",
              "                                                          2.32809946e-01,  1.90533817e-01, -1.27970979e-01,\n",
              "                                                          2.19601944e-01, -8.97296518e-03, -1.47258356e-01,\n",
              "                                                         -1.50244847e-01,  9.65000242e-02, -2.30589002e-01,\n",
              "                                                          3.74480970e-02, -1.42842263e-01, -2.95691355e-03,\n",
              "                                                         -2.22593531e-01,  9.03036632e-03, -2.20123470e-01,\n",
              "                                                          3.04106951e-01, -3.50562036e-01,  1.13571733e-01,\n",
              "                                                          3.17474902e-02,  3.21088165e-01, -3.76592308e-01,\n",
              "                                                         -1.79421082e-01, -2.81567145e-02,  2.03633204e-01,\n",
              "                                                          2.70664513e-01,  3.81687164e-01,  2.18241252e-02,\n",
              "                                                          5.14318421e-02, -2.02840507e-01, -2.86338925e-01,\n",
              "                                                          5.22647984e-02, -2.14318618e-01,  1.17477559e-01,\n",
              "                                                          8.69784579e-02,  2.72070944e-01, -3.12375367e-01,\n",
              "                                                         -2.03618214e-01,  2.33769566e-01, -5.46222851e-02,\n",
              "                                                         -1.41708583e-01,  4.93178129e-01,  2.52403647e-01,\n",
              "                                                          1.80762663e-01,  2.99385302e-02,  2.30650678e-01,\n",
              "                                                          2.85433661e-02, -1.67005181e-01, -1.19906716e-01,\n",
              "                                                         -3.05753231e-01,  1.09099172e-01, -1.10039748e-01,\n",
              "                                                         -4.97181341e-02, -6.84878901e-02, -1.16125368e-01,\n",
              "                                                         -2.64405519e-01, -1.93684742e-01,  1.51383847e-01,\n",
              "                                                          1.42586052e-01,  3.09520308e-02, -5.18710054e-02,\n",
              "                                                         -1.89637337e-02, -3.09769362e-01,  3.24176788e-01,\n",
              "                                                          1.82573218e-02,  1.13449886e-01, -3.29329669e-02,\n",
              "                                                          5.47595024e-02, -1.64488584e-01,  2.46628404e-01,\n",
              "                                                          2.19379365e-01,  5.05567491e-02, -2.05918863e-01,\n",
              "                                                         -4.81053069e-02, -3.35248113e-01, -3.71262699e-01,\n",
              "                                                          2.98686568e-02,  1.61681935e-01,  1.32273957e-01,\n",
              "                                                         -9.22437161e-02, -2.80546874e-01,  5.77581069e-03,\n",
              "                                                         -1.24849796e-01,  1.90567762e-01,  1.86713878e-02,\n",
              "                                                         -1.89652383e-01, -8.90014470e-02, -7.31021091e-02,\n",
              "                                                         -2.70371418e-02,  9.72744226e-02, -2.27419585e-01,\n",
              "                                                         -2.01727197e-01, -1.31910041e-01, -8.90411958e-02,\n",
              "                                                         -8.01959410e-02,  3.62815708e-01, -8.23133886e-02,\n",
              "                                                          3.23005408e-01, -1.66206568e-01,  2.99810972e-02,\n",
              "                                                         -2.18631789e-01,  1.54157251e-01, -7.05278888e-02,\n",
              "                                                          7.87688047e-02,  3.06480050e-01, -4.60609883e-01,\n",
              "                                                         -1.26457989e-01, -2.75467113e-02, -1.99332684e-01,\n",
              "                                                         -1.62988886e-01, -1.12007827e-01, -1.89190153e-02,\n",
              "                                                          2.29781464e-01, -3.75082284e-01,  2.05485269e-01,\n",
              "                                                         -1.25582248e-01,  2.07408816e-01, -7.40292519e-02,\n",
              "                                                         -2.52384841e-01, -1.65111944e-01, -1.05792994e-03,\n",
              "                                                          2.97220886e-01, -3.39884788e-01, -2.31276423e-01,\n",
              "                                                         -3.13523948e-01, -1.21313684e-01, -1.15696378e-01,\n",
              "                                                         -2.91161120e-01,  4.47792709e-01, -1.17111705e-01,\n",
              "                                                         -5.91077060e-02,  3.89682800e-02,  4.34918970e-01,\n",
              "                                                          2.18898758e-01,  1.77093700e-01,  2.57331967e-01,\n",
              "                                                          1.54466778e-02,  1.23435045e-02,  1.15800202e-01,\n",
              "                                                         -4.99329835e-01,  2.81453311e-01, -2.65423298e-01,\n",
              "                                                         -1.72715411e-01,  2.09310092e-04,  1.49799570e-01,\n",
              "                                                         -5.84728196e-02,  3.90332490e-02, -1.57950476e-01,\n",
              "                                                         -1.16589233e-01,  2.32454628e-01, -3.91801775e-01,\n",
              "                                                         -1.64537244e-02,  3.02010149e-01,  1.56892166e-01,\n",
              "                                                         -2.92346179e-01,  3.00201308e-02,  1.23217739e-01,\n",
              "                                                          3.87438148e-01,  5.00557385e-02, -2.48982713e-01,\n",
              "                                                          1.46280617e-01, -3.66703242e-01, -1.95138622e-02,\n",
              "                                                         -2.10361525e-01, -3.36472720e-01,  1.90122157e-01,\n",
              "                                                         -1.19202845e-01,  3.95769887e-02, -6.73276931e-02,\n",
              "                                                         -3.00761521e-01,  2.09262952e-01, -6.36380315e-02,\n",
              "                                                         -3.99043858e-02,  4.52284813e-01,  7.46198371e-02,\n",
              "                                                         -1.10166520e-01,  1.59099400e-01,  3.60119790e-02,\n",
              "                                                          1.97451673e-02, -9.89283696e-02,  2.86364615e-01,\n",
              "                                                          2.09338292e-01, -3.26606512e-01,  7.14745894e-02,\n",
              "                                                         -1.70978084e-01, -2.64413301e-02, -1.41204685e-01]], dtype=float32)>)])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF Converted RoBERTa model"
      ],
      "metadata": {
        "id": "OOOk35x433I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RoBERTaModel(keras.Model):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size, #50265\n",
        "        num_layers=12,\n",
        "        hidden_size=768,\n",
        "        dropout=0.1,\n",
        "        num_attention_heads=12,\n",
        "        inner_size=3072,\n",
        "        inner_activation=\"gelu\",\n",
        "        initializer_range=0.02,\n",
        "        max_sequence_length=512,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.inner_size = inner_size\n",
        "        self.inner_activation = keras.activations.get(inner_activation)\n",
        "        self.initializer_range = initializer_range\n",
        "        self.initializer = keras.initializers.TruncatedNormal(\n",
        "            stddev=initializer_range\n",
        "        )\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self._token_and_position_embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "            vocabulary_size=vocab_size,\n",
        "            sequence_length=max_sequence_length,\n",
        "            embedding_dim=hidden_size,\n",
        "            name=\"token_and_position_embeddings\"\n",
        "        )\n",
        "\n",
        "        self._embedding_norm_layer = keras.layers.LayerNormalization(\n",
        "            name=\"embeddings/layer_norm\",\n",
        "            axis=-1,\n",
        "            epsilon=1e-5,\n",
        "            dtype=tf.float32,\n",
        "        )\n",
        "\n",
        "        self._embedding_dropout = keras.layers.Dropout(\n",
        "            rate=dropout, name=\"embedding_dropout\"\n",
        "        )\n",
        "\n",
        "        self._transformer_layers = []\n",
        "        for i in range(num_layers):\n",
        "            layer = keras_nlp.layers.TransformerEncoder(\n",
        "                num_heads=num_attention_heads,\n",
        "                intermediate_dim=inner_size,\n",
        "                activation=self.inner_activation,\n",
        "                dropout=dropout,\n",
        "                kernel_initializer=self.initializer,\n",
        "                name=\"transformer/layer_%d\" % i,\n",
        "            )\n",
        "            self._transformer_layers.append(layer)\n",
        "\n",
        "        self.inputs = dict(\n",
        "            input_ids=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "            input_mask=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "            segment_ids=keras.Input(shape=(None,), dtype=tf.int32),\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if isinstance(inputs, dict):\n",
        "            input_ids = inputs.get(\"input_ids\")\n",
        "            input_mask = inputs.get(\"input_mask\")\n",
        "        else:\n",
        "            raise ValueError(f\"Inputs should be a dict. Received: {inputs}.\")\n",
        "\n",
        "        embeddings = self._token_and_position_embedding_layer(input_ids)\n",
        "        embeddings = self._embedding_norm_layer(embeddings)\n",
        "        embeddings = self._embedding_dropout(embeddings)\n",
        "\n",
        "        x = embeddings\n",
        "        for layer in self._transformer_layers:\n",
        "            x = layer(x, padding_mask=input_mask)\n",
        "        sequence_output = x\n",
        "        return sequence_output\n",
        "\n",
        "    def get_embedding_table(self):\n",
        "        return self._token_and_position_embedding_layer.token_embedding.embeddings\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update(\n",
        "            {\n",
        "                \"vocab_size\": self.vocab_size,\n",
        "                \"hidden_size\": self.hidden_size,\n",
        "                \"num_layers\": self.num_layers,\n",
        "                \"num_attention_heads\": self.num_attention_heads,\n",
        "                \"max_sequence_length\": self.max_sequence_length,\n",
        "                \"inner_size\": self.inner_size,\n",
        "                \"inner_activation\": keras.activations.serialize(\n",
        "                    self.inner_activation\n",
        "                ),\n",
        "                \"dropout\": self.dropout,\n",
        "                \"initializer_range\": self.initializer_range,\n",
        "            }\n",
        "        )\n",
        "        return config\n",
        "\n",
        "model = RoBERTaModel(vocab_size=50265)"
      ],
      "metadata": {
        "id": "Uz37rj0O8lgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('drive/MyDrive/tf_roberta_ckp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0b_CBcQ8qT4",
        "outputId": "2ca2bb40-1f12-44bf-a479-a71d1d12438e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff8792f0ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare"
      ],
      "metadata": {
        "id": "BAJ7nA6O-9z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ours = model(encoded_input.data)\n",
        "sum = tf.reduce_sum(ours)\n",
        "print(sum)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6J2s4hCP8yQu",
        "outputId": "6332853b-b5e7-481c-b4a9-9ad35acebde4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(168.82913, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.reduce_sum(lhs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFXZZaWb5Sy1",
        "outputId": "45a9fd5b-1133-4b94-ab26-aa4c92fe6cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=168.82816>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vo4n4F1M_ZKw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}